{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd035d4a",
   "metadata": {},
   "source": [
    "# How to Handle Missing Data\n",
    "If you want to type along with me, use [this notebook](https://humboldt.cloudbank.2i2c.cloud/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fbethanyj0%2Fdata271_sp24&branch=main&urlpath=tree%2Fdata271_sp24%2Fdemos%2Fdata271_demo35_live.ipynb) instead. \n",
    "If you don't want to type and want to follow along just by executing the cells, stay in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e99e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb544401",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import a dataset about Lake Mendocino\n",
    "df = pd.read_csv('coy_wy2024_csvdata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44604c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19791b",
   "metadata": {},
   "source": [
    "Based on this `.isna()` check, it appears this dataset has no null values. However, if we take a close look at the data. There are clearly some missing values. This dataset uses `-` in spaces that should be nulls. Some other columns use `0` where there should be nulls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469cb97",
   "metadata": {},
   "source": [
    "**Step 1:** Convert missing values to nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace dashes with nans\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .info to check on the zeros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfd7b7",
   "metadata": {},
   "source": [
    "They are type int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0 with nan in columns where the column name contains the word \"notes\"\n",
    "notes_columns = \n",
    "df[notes_columns] = \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61262abd",
   "metadata": {},
   "source": [
    "**Step 2** Analyze type and amount of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b59f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc3d2f9c",
   "metadata": {},
   "source": [
    "Some of of these columns have all almonst all missing data. These tend to be ones with \"notes\" in their column name. Maybe those columns are occasionally filled in during abnormal situations, but usually don't have entries. Some of the other columns have one missing data point. We'll treat the columns with many missing and columns with a few missing differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebcf724",
   "metadata": {},
   "source": [
    "**Step 3:** Decide on an approach. \n",
    "Some of of these columns have a lot of missing data. Let's drop those. Others can be imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns (axis = 1) that have more than 230 nan values (thresh = 230)\n",
    "df_dropped = \n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2bf626",
   "metadata": {},
   "source": [
    "Now we just have 4 columns with a missing value. We could drop those, but that isn't great for time series data. We don't want a gap in our time series (this can be problematic for many time series methods, so lets try to fill in the gaps (impute) instead. Let's first check on the distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561656a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert types before plotting distributions\n",
    "df_dropped = \n",
    "\n",
    "df_dropped.drop(columns = ['Top of Conservation High (ac-ft)', 'Top of Conservation (ac-ft)','Gross Pool','Gross Pool(elev)'],inplace=True)\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac3b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution to decide how to impute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac42f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution to decide how to impute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution to decide how to impute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c1919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check distribution to decide how to impute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean impute\n",
    "gross_mean = \n",
    "df_dropped['gross_pool'].fillna(gross_mean,inplace=True)\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c9cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean impute\n",
    "gross_mean_elev =\n",
    "df_dropped['gross_pool_elev'].fillna(gross_mean_elev,inplace=True)\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c63eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped[df_dropped.cons.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfc32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode impute\n",
    "cons_high_mode = df_dropped.cons_high.mode().values[0]\n",
    "df_dropped['cons_high'].fillna(cons_high_mode,inplace=True)\n",
    "cons_mode = df_dropped.cons.mode().values[0]\n",
    "df_dropped['cons'].fillna(cons_mode,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328eebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4de764",
   "metadata": {},
   "source": [
    "No more missing values!  \n",
    "**Step 4: Evaluate and compare** \n",
    "Let's try plotting through time to get a complete time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba506d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped['date'] = pd.to_datetime(df_dropped['ISO 8601 Date Time'].str[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde630d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.lineplot(data = df_dropped, x = 'date',y = 'cons');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed813c2c",
   "metadata": {},
   "source": [
    "Wait! This graph looks strange. It looks like the point we filled in is way different than what we might expect... Maybe a mode impute was *NOT* the right choice. It could have been better to use the points close in time to approximate our missing value. We will learn how to do that and other techniques in the next lecture. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
